# UAT Testing Workflow for setup-liquibase v1-beta
# This workflow provides comprehensive testing scenarios for the beta release

name: UAT Testing

on:
  workflow_dispatch:
    inputs:
      test_scenario:
        description: 'Test scenario to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - basic
        - platform
        - integration
        - error-handling

jobs:
  # Cross-platform tests - installation, compatibility, and caching across all platforms
  cross-platform-tests:
    if: ${{ github.event.inputs.test_scenario == 'all' || github.event.inputs.test_scenario == 'basic' || github.event.inputs.test_scenario == 'platform' }}
    name: "Cross-Platform Tests (${{ matrix.os }}) - Cache: ${{ matrix.cache }}"
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        version: ['4.32.0']
        cache: [true, false]
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Setup Liquibase
      id: setup-liquibase
      uses: ./
      with:
        version: ${{ matrix.version }}
        edition: 'oss'
        cache: ${{ matrix.cache }}
    
    - name: Verify Installation and Platform Compatibility
      shell: bash
      run: |
        echo "=== Cross-Platform Testing for ${{ matrix.os }} (Cache: ${{ matrix.cache }}) ==="
        
        # Test 1: Basic installation verification
        echo "1. Verifying Liquibase installation..."
        liquibase --version
        
        # Test 2: PATH and executable location
        echo "2. Testing executable location and PATH..."
        if [[ "${{ matrix.os }}" == "windows-latest" ]]; then
          echo "Testing Windows executable resolution..."
          cmd //c "where liquibase"
          LIQUIBASE_PATH=$(cmd //c "where liquibase" | head -1 | tr -d '\r')
          echo "Windows Liquibase path: $LIQUIBASE_PATH"
          
          # Verify Windows executable works
          if cmd //c "liquibase --help" > /dev/null 2>&1; then
            echo "✅ Windows executable works correctly"
          else
            echo "❌ Windows executable failed"
            exit 1
          fi
        else
          echo "Testing Unix executable resolution..."
          which liquibase
          LIQUIBASE_PATH=$(which liquibase)
          echo "Unix Liquibase path: $LIQUIBASE_PATH"
          
          # Verify Unix permissions and execution
          if [ -x "$LIQUIBASE_PATH" ]; then
            echo "✅ Unix executable has correct permissions"
          else
            echo "❌ Unix executable lacks execute permissions"
            ls -la "$LIQUIBASE_PATH"
            exit 1
          fi
        fi
        
        # Test 3: Action outputs validation
        echo "3. Validating action outputs..."
        VERSION_OUTPUT="${{ steps.setup-liquibase.outputs.liquibase-version }}"
        PATH_OUTPUT="${{ steps.setup-liquibase.outputs.liquibase-path }}"
        
        if [ -z "$VERSION_OUTPUT" ]; then
          echo "❌ liquibase-version output not set"
          exit 1
        fi
        echo "✅ Version output: $VERSION_OUTPUT"
        
        if [ -z "$PATH_OUTPUT" ]; then
          echo "❌ liquibase-path output not set"
          exit 1
        fi
        echo "✅ Path output: $PATH_OUTPUT"
        
        # Test 4: Platform-specific help command
        echo "4. Testing platform-specific help command..."
        liquibase --help | head -5
        
        echo "✅ Cross-platform tests completed successfully for ${{ matrix.os }}"
    
    - name: Test Cache Performance (Cache=true only)
      if: matrix.cache == true
      id: cached-install
      uses: ./
      with:
        version: ${{ matrix.version }}
        edition: 'oss'
        cache: true
    
    - name: Cache Performance Validation (Cache=true only)
      if: matrix.cache == true
      shell: bash
      run: |
        echo "=== Cache Performance Validation ==="
        
        # Validate cached install completed successfully
        echo "1. Cached installation completed successfully"
        liquibase --version
        
        # Compare outputs between first and cached install
        echo "2. Comparing installation outputs..."
        FIRST_VERSION="${{ steps.setup-liquibase.outputs.liquibase-version }}"
        CACHED_VERSION="${{ steps.cached-install.outputs.liquibase-version }}"
        
        if [ "$FIRST_VERSION" != "$CACHED_VERSION" ]; then
          echo "❌ Version mismatch between installs: $FIRST_VERSION vs $CACHED_VERSION"
          exit 1
        fi
        echo "✅ Version consistency verified: $FIRST_VERSION"
        
        FIRST_PATH="${{ steps.setup-liquibase.outputs.liquibase-path }}"
        CACHED_PATH="${{ steps.cached-install.outputs.liquibase-path }}"
        
        if [ "$FIRST_PATH" != "$CACHED_PATH" ]; then
          echo "❌ Path mismatch between installs: $FIRST_PATH vs $CACHED_PATH"
          exit 1
        fi
        echo "✅ Path consistency verified: $FIRST_PATH"
        
        echo "3. Cache performance test completed - installations are consistent"

  # Comprehensive Ubuntu-only tests - integration, error handling, and pro edition
  comprehensive-tests:
    if: ${{ github.event.inputs.test_scenario == 'all' || github.event.inputs.test_scenario == 'integration' || github.event.inputs.test_scenario == 'error-handling' }}
    name: Comprehensive Functionality Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Setup Liquibase for Integration Tests
      id: setup-integration
      uses: ./
      with:
        version: '4.32.0'
        edition: 'oss'
        cache: true
    
    # Integration Testing
    - name: Real-World Database Integration Tests
      run: |
        echo "=== Integration Testing - Real-World Database Operations ==="
        
        DB_URL="jdbc:h2:./comprehensive-test-db"
        echo "Using database: $DB_URL"
        
        # Test 1: Liquibase Update (Deploy changes)
        echo "1. Running Liquibase update (deploy changes)..."
        liquibase update \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 2: Liquibase Status (Check deployment status)
        echo "2. Checking deployment status..."
        liquibase status \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 3: Liquibase History (View deployment history)
        echo "3. Viewing deployment history..."
        liquibase history \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 4: Liquibase Tag (Create deployment tag)
        echo "4. Creating deployment tag..."
        liquibase tag comprehensive-test-tag \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 5: Liquibase Rollback (Rollback to tag)
        echo "5. Testing rollback to tag..."
        liquibase rollback comprehensive-test-tag \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 6: Verify Rollback Status
        echo "6. Verifying rollback completed..."
        liquibase status \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 7: Output validation
        echo "7. Validating action outputs..."
        VERSION_OUTPUT="${{ steps.setup-integration.outputs.liquibase-version }}"
        PATH_OUTPUT="${{ steps.setup-integration.outputs.liquibase-path }}"
        
        if [[ "$VERSION_OUTPUT" != *"4.32.0"* ]]; then
          echo "❌ Version output mismatch: expected 4.32.0, got $VERSION_OUTPUT"
          exit 1
        fi
        echo "✅ Version output validated: $VERSION_OUTPUT"
        
        if [ ! -d "$PATH_OUTPUT" ]; then
          echo "❌ Path output invalid: $PATH_OUTPUT does not exist"
          exit 1
        fi
        echo "✅ Path output validated: $PATH_OUTPUT"
        
        echo "✅ Integration tests completed successfully"
    
    # Error Handling Testing
    - name: Error Handling Tests
      run: |
        echo "=== Error Handling Testing ==="
        
        echo "Testing invalid configurations and error scenarios..."
    
    - name: Test Invalid Version (Should Fail)
      uses: ./
      continue-on-error: true
      id: invalid-version
      with:
        version: 'invalid-version'
        edition: 'oss'
    
    - name: Verify Invalid Version Failed
      run: |
        if [ "${{ steps.invalid-version.outcome }}" == "success" ]; then
          echo "ERROR: Invalid version test should have failed!"
          exit 1
        fi
        echo "✅ Invalid version correctly rejected"
    
    - name: Test Unsupported Version (Should Fail)
      uses: ./
      continue-on-error: true
      id: unsupported-version
      with:
        version: '4.25.0'
        edition: 'oss'
    
    - name: Verify Unsupported Version Failed
      run: |
        if [ "${{ steps.unsupported-version.outcome }}" == "success" ]; then
          echo "ERROR: Unsupported version test should have failed!"
          exit 1
        fi
        echo "✅ Unsupported version correctly rejected"
    
    - name: Test Invalid Edition (Should Fail)
      uses: ./
      continue-on-error: true
      id: invalid-edition
      with:
        version: '4.32.0'
        edition: 'invalid'
    
    - name: Verify Invalid Edition Failed
      run: |
        if [ "${{ steps.invalid-edition.outcome }}" == "success" ]; then
          echo "ERROR: Invalid edition test should have failed!"
          exit 1
        fi
        echo "✅ Invalid edition correctly rejected"
    
    - name: Test Pro Edition Without License (Should Fail)
      uses: ./
      continue-on-error: true
      id: pro-no-license
      with:
        version: '4.32.0'
        edition: 'pro'
    
    - name: Verify Pro Without License Failed
      run: |
        if [ "${{ steps.pro-no-license.outcome }}" == "success" ]; then
          echo "ERROR: Pro without license test should have failed!"
          exit 1
        fi
        echo "✅ Pro edition without license correctly rejected"
    
    # Pro Edition Testing
    - name: Check Pro License Availability
      id: check-license
      run: |
        if [ -n "${{ secrets.PRO_LICENSE_KEY }}" ]; then
          echo "has_license=true" >> $GITHUB_OUTPUT
        else
          echo "has_license=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Test Pro Edition (If License Available)
      if: steps.check-license.outputs.has_license == 'true'
      uses: ./
      with:
        version: '4.32.0'
        edition: 'pro'
        cache: true
      env:
        LIQUIBASE_LICENSE_KEY: ${{ secrets.PRO_LICENSE_KEY }}
    
    - name: Verify Pro Installation
      if: steps.check-license.outputs.has_license == 'true'
      run: |
        liquibase --version
        echo "✅ Pro edition installed successfully"
    
    - name: Skip Pro Tests (No License)
      if: steps.check-license.outputs.has_license == 'false'
      run: |
        echo "⏩ Skipping Pro edition tests - no license key available"
        echo "To test Pro edition, add PRO_LICENSE_KEY secret to the repository"

  # Summary job
  uat-summary:
    name: UAT Test Summary
    needs: [cross-platform-tests, comprehensive-tests]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Generate Test Summary
      run: |
        echo "# UAT Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "## Test Results" >> $GITHUB_STEP_SUMMARY
        echo "| Test Category | Status | Coverage |" >> $GITHUB_STEP_SUMMARY
        echo "|---------------|--------|----------|" >> $GITHUB_STEP_SUMMARY
        echo "| Cross-Platform Tests | ${{ needs.cross-platform-tests.result == 'success' && '✅ PASSED' || needs.cross-platform-tests.result == 'skipped' && '⏩ SKIPPED' || '❌ FAILED' }} | Ubuntu, Windows, macOS × Cache validation |" >> $GITHUB_STEP_SUMMARY
        echo "| Comprehensive Tests | ${{ needs.comprehensive-tests.result == 'success' && '✅ PASSED' || needs.comprehensive-tests.result == 'skipped' && '⏩ SKIPPED' || '❌ FAILED' }} | Integration, Error Handling, Pro Edition |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Overall result
        if [[ "${{ needs.cross-platform-tests.result }}" == "success" || "${{ needs.cross-platform-tests.result }}" == "skipped" ]] && 
           [[ "${{ needs.comprehensive-tests.result }}" == "success" || "${{ needs.comprehensive-tests.result }}" == "skipped" ]]; then
          echo "## 🎉 Overall Result: PASSED" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All critical UAT tests have passed. The v1-beta release is ready for broader testing." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Coverage Summary:" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Cross-Platform Compatibility**: Ubuntu, Windows, macOS" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Installation & Caching**: Both cached and uncached scenarios" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Real-World Integration**: Database operations, deployment workflows" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Error Handling**: Invalid inputs, missing licenses, unsupported versions" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ **Pro Edition**: License validation and Pro-specific functionality" >> $GITHUB_STEP_SUMMARY
        else
          echo "## ❌ Overall Result: FAILED" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Some UAT tests have failed. Please review the results and address issues before promoting to v1.0.0." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Optimized Test Matrix" >> $GITHUB_STEP_SUMMARY
        echo "This UAT workflow uses an optimized hybrid approach:" >> $GITHUB_STEP_SUMMARY
        echo "- **Cross-Platform Tests**: 6 jobs (3 OS × 2 cache scenarios)" >> $GITHUB_STEP_SUMMARY
        echo "- **Comprehensive Tests**: 1 job (Ubuntu-only functionality testing)" >> $GITHUB_STEP_SUMMARY
        echo "- **Total**: 7 jobs (reduced from 14) with same coverage and faster feedback" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "- Review any failed tests" >> $GITHUB_STEP_SUMMARY
        echo "- Test on additional platforms if needed" >> $GITHUB_STEP_SUMMARY
        echo "- Share feedback via GitHub Issues with label 'uat-testing'" >> $GITHUB_STEP_SUMMARY
        echo "- When ready, promote to v1.0.0 and publish to GitHub Marketplace" >> $GITHUB_STEP_SUMMARY