# UAT Testing Workflow for setup-liquibase v1-beta
# This workflow provides comprehensive testing scenarios for the beta release

name: UAT Testing

on:
  workflow_dispatch:
    inputs:
      test_scenario:
        description: 'Test scenario to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - basic
        - platform
        - integration
        - error-handling

jobs:
  # Basic functionality tests
  basic-tests:
    if: ${{ github.event.inputs.test_scenario == 'all' || github.event.inputs.test_scenario == 'basic' }}
    name: "Basic Tests (${{ matrix.os }}) - Cache: ${{ matrix.cache }}"
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        version: ['4.32.0']
        cache: [true, false]
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Test Setup Liquibase OSS
      id: setup-liquibase
      uses: ./
      with:
        version: ${{ matrix.version }}
        edition: 'oss'
        cache: ${{ matrix.cache }}
    
    - name: Verify Installation
      shell: bash
      run: |
        echo "Testing Liquibase installation..."
        
        # Check if liquibase is in PATH
        which liquibase || (echo "ERROR: liquibase not found in PATH" && exit 1)
        
        # Check version output
        liquibase --version
        
        # Verify outputs
        echo "Version output: ${{ steps.setup-liquibase.outputs.liquibase-version }}"
        echo "Path output: ${{ steps.setup-liquibase.outputs.liquibase-path }}"
        
        if [ -z "${{ steps.setup-liquibase.outputs.liquibase-version }}" ]; then
          echo "ERROR: liquibase-version output not set"
          exit 1
        fi
        
        if [ -z "${{ steps.setup-liquibase.outputs.liquibase-path }}" ]; then
          echo "ERROR: liquibase-path output not set"
          exit 1
        fi
    
    - name: Test Cache Performance (Second Install)
      id: cached-install
      uses: ./
      with:
        version: ${{ matrix.version }}
        edition: 'oss'
        cache: true
    
    - name: Cache Performance Validation
      shell: bash
      run: |
        echo "=== Cache Performance Validation ==="
        
        # Validate that cached install completed successfully
        echo "1. Cached installation completed successfully"
        liquibase --version
        
        # Compare outputs between first and cached install
        echo "2. Comparing installation outputs..."
        FIRST_VERSION="${{ steps.setup-liquibase.outputs.liquibase-version }}"
        CACHED_VERSION="${{ steps.cached-install.outputs.liquibase-version }}"
        
        if [ "$FIRST_VERSION" != "$CACHED_VERSION" ]; then
          echo "❌ Version mismatch between installs: $FIRST_VERSION vs $CACHED_VERSION"
          exit 1
        fi
        echo "✅ Version consistency verified: $FIRST_VERSION"
        
        FIRST_PATH="${{ steps.setup-liquibase.outputs.liquibase-path }}"
        CACHED_PATH="${{ steps.cached-install.outputs.liquibase-path }}"
        
        if [ "$FIRST_PATH" != "$CACHED_PATH" ]; then
          echo "❌ Path mismatch between installs: $FIRST_PATH vs $CACHED_PATH"
          exit 1
        fi
        echo "✅ Path consistency verified: $FIRST_PATH"
        
        echo "3. Cache performance test completed - installations are consistent"

  # Platform-specific tests - focus on basic compatibility and platform differences
  platform-tests:
    if: ${{ github.event.inputs.test_scenario == 'platform' }}
    name: "Platform Compatibility (${{ matrix.os }})"
    strategy:
      fail-fast: false
      matrix:
        include:
        - os: ubuntu-latest
          version: '4.32.0'
        - os: windows-latest
          version: '4.32.0'
        - os: macos-latest
          version: '4.32.0'
    runs-on: ${{ matrix.os }}
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Setup Liquibase
      id: setup
      uses: ./
      with:
        version: ${{ matrix.version }}
        edition: 'oss'
        cache: false
    
    - name: Test Platform Compatibility
      shell: bash
      run: |
        echo "=== Platform Compatibility Testing for ${{ matrix.os }} ==="
        
        # Test 1: Basic installation verification
        echo "1. Verifying Liquibase installation..."
        liquibase --version
        
        # Test 2: Platform-specific executable location and PATH
        echo "2. Testing executable location and PATH..."
        if [[ "${{ matrix.os }}" == "windows-latest" ]]; then
          echo "Testing Windows executable resolution..."
          cmd //c "where liquibase"
          LIQUIBASE_PATH=$(cmd //c "where liquibase" | head -1 | tr -d '\r')
          echo "Windows Liquibase path: $LIQUIBASE_PATH"
          
          # Verify it's actually executable on Windows
          if cmd //c "liquibase --help" > /dev/null 2>&1; then
            echo "✅ Windows executable works correctly"
          else
            echo "❌ Windows executable failed"
            exit 1
          fi
        else
          echo "Testing Unix executable resolution..."
          which liquibase
          LIQUIBASE_PATH=$(which liquibase)
          echo "Unix Liquibase path: $LIQUIBASE_PATH"
          
          # Verify permissions and execution on Unix
          if [ -x "$LIQUIBASE_PATH" ]; then
            echo "✅ Unix executable has correct permissions"
          else
            echo "❌ Unix executable lacks execute permissions"
            ls -la "$LIQUIBASE_PATH"
            exit 1
          fi
        fi
        
        # Test 3: Action outputs validation
        echo "3. Validating action outputs..."
        VERSION_OUTPUT="${{ steps.setup.outputs.liquibase-version }}"
        PATH_OUTPUT="${{ steps.setup.outputs.liquibase-path }}"
        
        if [ -z "$VERSION_OUTPUT" ]; then
          echo "❌ liquibase-version output not set"
          exit 1
        fi
        echo "✅ Version output: $VERSION_OUTPUT"
        
        if [ -z "$PATH_OUTPUT" ]; then
          echo "❌ liquibase-path output not set"
          exit 1
        fi
        echo "✅ Path output: $PATH_OUTPUT"
        
        # Test 4: Platform-specific help command
        echo "4. Testing platform-specific help command..."
        liquibase --help | head -5
        
        echo "✅ Platform compatibility tests completed successfully for ${{ matrix.os }}"

  # Integration tests with real database operations - cross-platform real-world scenarios
  integration-tests:
    if: ${{ github.event.inputs.test_scenario == 'all' || github.event.inputs.test_scenario == 'integration' }}
    name: "Integration Tests (${{ matrix.os }})"
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        version: ['4.32.0']
    runs-on: ${{ matrix.os }}
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Setup Liquibase
      id: setup
      uses: ./
      with:
        version: ${{ matrix.version }}
        edition: 'oss'
        cache: true
    
    - name: Real-World Database Integration Test
      shell: bash
      run: |
        echo "=== Real-World Integration Testing on ${{ matrix.os }} ==="
        
        # Use platform-specific database file naming
        if [[ "${{ matrix.os }}" == "windows-latest" ]]; then
          DB_URL="jdbc:h2:./integration-test-db"
        else
          DB_URL="jdbc:h2:./integration-test-db"
        fi
        
        echo "Using database: $DB_URL"
        
        # Test 1: Liquibase Update (Deploy changes)
        echo "1. Running Liquibase update (deploy changes)..."
        liquibase update \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 2: Liquibase Status (Check deployment status)
        echo "2. Checking deployment status..."
        liquibase status \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 3: Liquibase History (View deployment history)
        echo "3. Viewing deployment history..."
        liquibase history \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 4: Liquibase Tag (Create deployment tag)
        echo "4. Creating deployment tag..."
        liquibase tag uat-test-tag \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 5: Liquibase Rollback (Rollback to tag)
        echo "5. Testing rollback to tag..."
        liquibase rollback uat-test-tag \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 6: Verify Rollback Status
        echo "6. Verifying rollback completed..."
        liquibase status \
          --changelog-file=changelog.xml \
          --url="$DB_URL" \
          --username=sa \
          --password=
        
        # Test 7: Output validation
        echo "7. Validating action outputs..."
        VERSION_OUTPUT="${{ steps.setup.outputs.liquibase-version }}"
        PATH_OUTPUT="${{ steps.setup.outputs.liquibase-path }}"
        
        if [[ "$VERSION_OUTPUT" != *"${{ matrix.version }}"* ]]; then
          echo "❌ Version output mismatch: expected ${{ matrix.version }}, got $VERSION_OUTPUT"
          exit 1
        fi
        echo "✅ Version output validated: $VERSION_OUTPUT"
        
        if [ ! -d "$PATH_OUTPUT" ]; then
          echo "❌ Path output invalid: $PATH_OUTPUT does not exist"
          exit 1
        fi
        echo "✅ Path output validated: $PATH_OUTPUT"
        
        echo "✅ Integration tests completed successfully on ${{ matrix.os }}"

  # Error handling tests
  error-handling-tests:
    if: ${{ github.event.inputs.test_scenario == 'all' || github.event.inputs.test_scenario == 'error-handling' }}
    name: Error Handling Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Test Invalid Version (Should Fail)
      uses: ./
      continue-on-error: true
      id: invalid-version
      with:
        version: 'invalid-version'
        edition: 'oss'
    
    - name: Verify Invalid Version Failed
      run: |
        if [ "${{ steps.invalid-version.outcome }}" == "success" ]; then
          echo "ERROR: Invalid version test should have failed!"
          exit 1
        fi
        echo "✅ Invalid version correctly rejected"
    
    - name: Test Unsupported Version (Should Fail)
      uses: ./
      continue-on-error: true
      id: unsupported-version
      with:
        version: '4.25.0'
        edition: 'oss'
    
    - name: Verify Unsupported Version Failed
      run: |
        if [ "${{ steps.unsupported-version.outcome }}" == "success" ]; then
          echo "ERROR: Unsupported version test should have failed!"
          exit 1
        fi
        echo "✅ Unsupported version correctly rejected"
    
    - name: Test Invalid Edition (Should Fail)
      uses: ./
      continue-on-error: true
      id: invalid-edition
      with:
        version: '4.32.0'
        edition: 'invalid'
    
    - name: Verify Invalid Edition Failed
      run: |
        if [ "${{ steps.invalid-edition.outcome }}" == "success" ]; then
          echo "ERROR: Invalid edition test should have failed!"
          exit 1
        fi
        echo "✅ Invalid edition correctly rejected"
    
    - name: Test Pro Edition Without License (Should Fail)
      uses: ./
      continue-on-error: true
      id: pro-no-license
      with:
        version: '4.32.0'
        edition: 'pro'
    
    - name: Verify Pro Without License Failed
      run: |
        if [ "${{ steps.pro-no-license.outcome }}" == "success" ]; then
          echo "ERROR: Pro without license test should have failed!"
          exit 1
        fi
        echo "✅ Pro edition without license correctly rejected"

  # Pro edition tests (only if license is available)
  pro-edition-tests:
    if: ${{ github.event.inputs.test_scenario == 'all' || github.event.inputs.test_scenario == 'basic' }}
    name: Pro Edition Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Check License Availability
      id: check-license
      run: |
        if [ -n "${{ secrets.PRO_LICENSE_KEY }}" ]; then
          echo "has_license=true" >> $GITHUB_OUTPUT
        else
          echo "has_license=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Test Pro Edition (If License Available)
      if: steps.check-license.outputs.has_license == 'true'
      uses: ./
      with:
        version: '4.32.0'
        edition: 'pro'
        cache: true
      env:
        LIQUIBASE_LICENSE_KEY: ${{ secrets.PRO_LICENSE_KEY }}
    
    - name: Verify Pro Installation
      if: steps.check-license.outputs.has_license == 'true'
      run: |
        liquibase --version
        echo "✅ Pro edition installed successfully"
    
    - name: Skip Pro Tests (No License)
      if: steps.check-license.outputs.has_license == 'false'
      run: |
        echo "⏩ Skipping Pro edition tests - no license key available"
        echo "To test Pro edition, add PRO_LICENSE_KEY secret to the repository"

  # Summary job
  uat-summary:
    name: UAT Test Summary
    needs: [basic-tests, platform-tests, integration-tests, error-handling-tests, pro-edition-tests]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Generate Test Summary
      run: |
        echo "# UAT Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "## Test Results" >> $GITHUB_STEP_SUMMARY
        echo "| Test Category | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|---------------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Basic Tests | ${{ needs.basic-tests.result == 'success' && '✅ PASSED' || needs.basic-tests.result == 'skipped' && '⏩ SKIPPED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Platform Tests | ${{ needs.platform-tests.result == 'success' && '✅ PASSED' || needs.platform-tests.result == 'skipped' && '⏩ SKIPPED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && '✅ PASSED' || needs.integration-tests.result == 'skipped' && '⏩ SKIPPED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Error Handling Tests | ${{ needs.error-handling-tests.result == 'success' && '✅ PASSED' || needs.error-handling-tests.result == 'skipped' && '⏩ SKIPPED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Pro Edition Tests | ${{ needs.pro-edition-tests.result == 'success' && '✅ PASSED' || needs.pro-edition-tests.result == 'skipped' && '⏩ SKIPPED' || '❌ FAILED' }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Overall result
        if [[ "${{ needs.basic-tests.result }}" == "success" && 
              "${{ needs.platform-tests.result }}" == "success" && 
              "${{ needs.integration-tests.result }}" == "success" && 
              "${{ needs.error-handling-tests.result }}" == "success" ]]; then
          echo "## 🎉 Overall Result: PASSED" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "All critical UAT tests have passed. The v1-beta release is ready for broader testing." >> $GITHUB_STEP_SUMMARY
        else
          echo "## ❌ Overall Result: FAILED" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Some UAT tests have failed. Please review the results and address issues before promoting to v1.0.0." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "- Review any failed tests" >> $GITHUB_STEP_SUMMARY
        echo "- Test on additional platforms if needed" >> $GITHUB_STEP_SUMMARY
        echo "- Share feedback via GitHub Issues with label 'uat-testing'" >> $GITHUB_STEP_SUMMARY
        echo "- When ready, promote to v1.0.0 and publish to GitHub Marketplace" >> $GITHUB_STEP_SUMMARY